{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> **ISO2024 INTRODUCTORY SPATIAL 'OMICS ANALYSIS**\n",
    ">\n",
    ">\n",
    ">- HYBRID : TORONTO & ZOOM\n",
    ">- 9TH JULY 2024 <br>\n",
    "\n",
    "\n",
    ">**Module 2 : Pre-processing steps**<BR>\n",
    ">   * A. Understanding your output *\n",
    ">   * B. Tidying and pre-evaluating your data *\n",
    "\n",
    ">\n",
    ">**Instructor : Shamini Ayyadhury**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "MODULE 2 : SUPPLEMENTARY SCRIPT 01 - PERFORMING QUALITY CONTROL STEPS OVER WT MOUSE SAMPLE \n",
    "Repeat of module2___script01_pre_processing_steps.ipynb but the wildtpe mouse sample will be processed and saved.\n",
    "Both wildtype and AD data output will be used for module 5/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import the following libraries\n",
    "\n",
    "### Packages for general system functions, miscellaneous operating system interfaces, warning control system\n",
    "import sys ### general system functions\n",
    "import os ### miscellaneous operating system interfaces\n",
    "import warnings ### warning control system\n",
    "import psutil\n",
    "warnings.filterwarnings('ignore') ### ignore warnings\n",
    "\n",
    "### Packages for data manipulation and analysis, data visualization\n",
    "import pandas as pd ### data manipulation and analysis for tabular data in python\n",
    "import matplotlib.pyplot as plt ### plotting library for the Python programming language and its numerical mathematics extension NumPy\n",
    "import seaborn as sns ### data visualization library based on matplotlib (my personal favourite over matplotlib)\n",
    "import numpy as np ### support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sys.path.append('~/data/projects/spatial_workshop/')\n",
    "import pre_processing_fnc as ppf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### its sometimes useful to assign the file names or paths to variables to avoid typing errors\n",
    "\n",
    "### path variables\n",
    "data_dir = '~/data1/data_orig/data/spatial/xenium/10xGenomics/' ### data directory\n",
    "out = '~/data/projects/spatial_workshop/out/module2/' ### output directory for saving files. We have created these output directories in advance to save time. Participants are free to create their own if they wish to.\n",
    "os.makedirs(out, exist_ok=True) ### create a new directory for saving files (but checks if the directory already exists)\n",
    "\n",
    "\n",
    "### object variables\n",
    "datasets_to_use = 'mice_AD_model/wt/xenium_out/' ### the name of the dataset to use\n",
    "features_filepath = 'cell_feature_matrix.h5'\n",
    "cells_filename = 'cells.parquet'\n",
    "transcripts_filename = 'transcripts.parquet'\n",
    "metrices_filename = 'metrics_summary.csv'\n",
    "\n",
    "\n",
    "ppf.get_memory_usage() ### monitor memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### we will load 3 files here: cell_feature_matrix.h5, cells.parquet and transcripts.parquet\n",
    "### We will check the parquet file to ensure that the string values are not in bytes format and if they are to convert them back to string\n",
    "df_cell = ppf.check_parquet(os.path.join(data_dir+datasets_to_use ,cells_filename))\n",
    "df_transcript = ppf.check_parquet(os.path.join(data_dir+datasets_to_use, transcripts_filename))\n",
    "df_metric = pd.read_csv(os.path.join(data_dir+datasets_to_use, metrices_filename))\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------\n",
    "ppf.get_memory_usage() ### monitor memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze transcript QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "processed_data = ppf.process_data(df_transcript) ### we process and assign the output to an object called processed_data\n",
    "del df_transcript ### we delete the original transcript dataframe to save memory\n",
    "\n",
    "\n",
    "#------------------------------------------------\n",
    "ppf.get_memory_usage() ### monitor memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data.head()\n",
    "### note the additional columns added to the processed_data dataframe : group and binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The cleaned data is then used to create the gene matrix, control matrix, counts matrix and cell centroid matrix \n",
    "Here, it involves removing low quality transcripts and assigning the transcripts to the cells based on the cell segmentation from the standard xenium clear_output\n",
    "We still keep the negative control values as a separate matrix\n",
    "\n",
    "However the 3 matrices that we will bring forward to the next lesson are\n",
    "1. gene matrix\n",
    "2. counts matrix\n",
    "3. cell centroid matrix\n",
    "\"\"\"\n",
    "\n",
    "df_counts, transcripts_df, gene_mtx, neg_mtx, centroids = ppf.clean_processed_tf(processed_data)\n",
    "\n",
    "\n",
    "#------------------------------------------------\n",
    "ppf.get_memory_usage() ### monitor memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs(out+'wt_13_4mths', exist_ok=True)\n",
    "\n",
    "\n",
    "df_counts.to_csv(out+'wt_13_4mths/df_counts.csv', index=True)\n",
    "gene_mtx.to_csv(out+'wt_13_4mths/gene_mtx.csv', index=True)\n",
    "neg_mtx.to_csv(out+'wt_13_4mths/neg_mtx.csv', index=True)\n",
    "centroids.to_csv(out+'wt_13_4mths/centroids.csv', index=True)\n",
    "transcripts_df.to_csv(out+'wt_13_4mths/transcripts_df.csv', index=True)\n",
    "\n",
    "ppf.get_memory_usage() ### monitor memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc ### scanpy is a package for single-cell analysis in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.AnnData(X=gene_mtx, var=pd.DataFrame(index=gene_mtx.columns.values))\n",
    "\n",
    "df_counts = df_counts[df_counts.index.isin(gene_mtx.index)]\n",
    "\n",
    "df_counts = df_counts.reindex(gene_mtx.index)\n",
    "adata.obs = df_counts.copy()\n",
    "    \n",
    "centroids = centroids.reindex(adata.obs.index)\n",
    "adata.obs[['x_location', 'y_location']] = centroids[['centroid_x', 'centroid_y']].values\n",
    "\n",
    "gene_mtx_bool = gene_mtx > 0\n",
    "n_cells = gene_mtx_bool.sum(axis=0)\n",
    "n_genes = gene_mtx_bool.sum(axis=1)\n",
    "\n",
    "adata.var['n_cells'] = n_cells\n",
    "adata.obs['n_genes'] = n_genes\n",
    "\n",
    "sc.pp.filter_genes(adata, min_cells=3)\n",
    "sc.pp.filter_cells(adata, min_counts=9)\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------\n",
    "ppf.get_memory_usage() ### monitor memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_genes = gene_mtx_bool.sum(axis=1)\n",
    "adata.obs['n_genes'] = n_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(7, 5))\n",
    "\n",
    "\n",
    "median = np.median(adata.obs['n_genes'])\n",
    "mean = np.mean(adata.obs['n_genes'])\n",
    "\n",
    "adata.uns['n_genes_med'] = median\n",
    "adata.uns['n_genes_mean'] = mean\n",
    "\n",
    "### first look at counts distribution\n",
    "ax = sns.histplot(adata.obs['n_genes'], bins=180, color='gray')\n",
    "ax.axvline(median, color='red', linestyle='--', label='median')\n",
    "ax.axvline(mean, color='blue', linestyle='--', label='mean')\n",
    "ax.legend()\n",
    "ax.set_title('B2C. Genes expressed per cell distribution')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------\n",
    "ppf.get_memory_usage() ### monitor memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Always remember to save the coordinates of the spatial data in the adata object into the uns and obsm slots. Many methods call the spatial coordinates from these slots\n",
    "\n",
    "adata.obsm['spatial'] = adata.obs[['x_location', 'y_location']].values\n",
    "adata.uns['spatial'] = {'spatial' : adata.obsm['spatial'].copy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save your adata\n",
    "adata.raw = adata\n",
    "adata.write(out+'wt_13_4mths/adata_wt.h5ad')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xenium",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
