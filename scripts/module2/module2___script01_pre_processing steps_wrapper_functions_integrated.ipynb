{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> **ISO2024 INTRODUCTORY SPATIAL 'OMICS ANALYSIS**\n",
    ">\n",
    ">\n",
    ">- HYBRID : TORONTO & ZOOM\n",
    ">- 9TH JULY 2024 <br>\n",
    "\n",
    "\n",
    ">**Module 2 : Pre-processing steps**<BR>\n",
    ">   * A. Understanding your output *\n",
    ">   * B. Tidying and pre-evaluating your data *\n",
    "\n",
    ">\n",
    ">**Instructor : Shamini Ayyadhury**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "A. UNDERSTANDING YOUR OUTPUT\n",
    "```\n",
    "01. analysis_summary.html\n",
    "02. analysis.tar\n",
    "03. analysis.zarr.zip\n",
    "04. cell_boundaries.csv \n",
    "05. cell_boundaries.parquet ***\n",
    "06. cell_feature_matrix\n",
    "07. cell_feature_matrix.h5 ***\n",
    "08. cell_feature_matrix.tar\n",
    "09. cell_feature_matrix.zarr.zip\n",
    "10. cells.csv \n",
    "11. cells.parquet ***\n",
    "12. cells.zarr.zip\n",
    "13. experiment.xenium\n",
    "14. gene_panel.json\n",
    "15. metrics_summary.csv\n",
    "16. morphology_focus.ome.tif\n",
    "17. morphology_mip.ome.tif\n",
    "18. morphology.ome.tif ***\n",
    "19. nucleus_boundaries.csv\n",
    "20. nucleus_boundaries.parquet ***\n",
    "21. transcripts.csv\n",
    "22. transcripts.parquet ***\n",
    "23. transcripts.zarr.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "B. TIDYING AND PRE-EVALUATING YOUR DATA\n",
    "```\n",
    "In this section participants will review the transcripts file. The transcripts file contains the identity, position of each transcript from genes and controls. Here we will start from this file and review the quality values and assess cut-off margins. \n",
    "\n",
    "OBJECTIVES\n",
    "1. Process transcript file and evaluate quality of gene and control transcripts\n",
    "2. Assess the distribution of transcripts across 'field of view'.\n",
    "3. Derive the gene matrix, counts matrix and cell centroid matrix from the transcript file\n",
    "\n",
    "DATASETS WE WILL USE\n",
    "* We will use the FFPE half-brain xenium sample - \"TgCRND8 17.9 months\" for this first script\n",
    "This is a transgenic mouse model for Alzheimer's disease pathology\n",
    "\"https://www.10xgenomics.com/datasets/xenium-in-situ-analysis-of-alzheimers-disease-mouse-model-brain-coronal-sections-from-one-hemisphere-over-a-time-course-1-standard\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "* We will be using some packages routinely throughput this workshop. \n",
    "* Wrapper functions are provided where necessary.\n",
    "    * The reason being, the purpose of this workshop is not to bias anyone towards any standard or popular packages but to deliver an understanding as to what is happenning.\n",
    "    * There are multiple different tools out there and the purpose of this workshop is to give you the necessary knowledge to understand what is happenning under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    ">>> PACKAGE IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import the following libraries\n",
    "\n",
    "### Packages for general system functions, miscellaneous operating system interfaces, warning control system\n",
    "import sys ### general system functions\n",
    "import os ### miscellaneous operating system interfaces\n",
    "import warnings ### warning control system\n",
    "import psutil\n",
    "import psutil ### module providing an interface for retrieving information on all running processes and system utilization (CPU, memory, disks, network, sensors) in a portable way by using Python\n",
    "import gc ### garbage collector interface\n",
    "import os ### miscellaneous operating system interfaces\n",
    "\n",
    "warnings.filterwarnings('ignore') ### ignore warnings\n",
    "\n",
    "### Packages for data manipulation and analysis, data visualization\n",
    "import pandas as pd ### data manipulation and analysis for tabular data in python\n",
    "import matplotlib.pyplot as plt ### plotting library for the Python programming language and its numerical mathematics extension NumPy\n",
    "from matplotlib import colors as mcolors\n",
    "import seaborn as sns ### data visualization library based on matplotlib (my personal favourite over matplotlib)\n",
    "import numpy as np ### support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays\n",
    "import scanpy as sc ### single-cell RNA-seq analysis in Python\n",
    "from IPython.display import display, HTML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    ">>> WRAPPER FUNCTIONS - ONLY FOR MODULE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The \"pre_processing_fnc\" is a custom python script that contains all the functions required for pre-processing the data.\n",
    "These are wrapper functions written specifically for this workshop to help participants understand the pre-processing steps and to save time.\n",
    "This package is available in the \"spatial_workshop\" repository where participants are encouraged to look at the exact codes and scripts after lessons.\n",
    "\n",
    "The functions in this script include:\n",
    "\n",
    "1. check_parquet\n",
    "Sometimes, there is an issue when loading .parquet files, the string values end up as bytes. This function checks for this issue and fixes it.\n",
    "\n",
    "2. process_data\n",
    "This function will label the transcripts as gene or control and as assigned to a cell or not\n",
    "\n",
    "3. clean_processed_tf\n",
    "This function will remove low quality transcripts and give 4 matrices as output: gene matrix file, control matrix file, counts matrix and cell centroid matrix\n",
    "\n",
    "4. process_adata\n",
    "8. prepare_adata\n",
    "This wrapper will process the centroid matrix, gene matrix and counts matrix properlt to create anndata object\n",
    "\n",
    "5. fov_plot\n",
    "A function to plot the field of view (FOV) images that saves time for participants to visualize the data.\n",
    "\n",
    "6. plot_gene_and_neg_transcripts\n",
    "Another function to plot the gene and negative transcripts and assess their QV values that saves time for participants to visualize the data.\n",
    "\n",
    "7. display_side_by_side\n",
    "\n",
    "An image plotting wrapper\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#sys.path.append('/home/shamini/data/projects/spatial_workshop/')\n",
    "\n",
    "#import pre_processing_fnc as ppf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    ">>> MANAGING YOUR FOLDER AND FILE PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### its sometimes useful to assign the file names or paths to variables to avoid typing errors\n",
    "\n",
    "### path variables\n",
    "data_dir = '/home/shamini/data1/data_orig/data/spatial/xenium/10xGenomics/' ### data directory\n",
    "out = '/home/shamini/data/projects/spatial_workshop/out/module2/' ### output directory for saving files. We have created these output directories in advance to save time. Participants are free to create their own if they wish to.\n",
    "os.makedirs(out, exist_ok=True) ### create a new directory for saving files (but checks if the directory already exists)\n",
    "\n",
    "### object variables\n",
    "datasets_to_use = 'mice_AD_model/TgCRND8/xenium_out/' ### the name of the dataset to use\n",
    "features_filepath = 'cell_feature_matrix.h5'\n",
    "cells_filename = 'cells.parquet'\n",
    "transcripts_filename = 'transcripts.parquet'\n",
    "metrices_filename = 'metrics_summary.csv'\n",
    "\n",
    "\n",
    "### MEMORY USAGE\n",
    "### Run th following code to check the memory usage\n",
    "### THe following function is found in the pre_processing_fnc folder\n",
    "def get_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_info = process.memory_info()\n",
    "    return f\"Memory usage: {mem_info.rss / (1024 ** 2):.2f} MB\"\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "#------------------------------------------------\n",
    "get_memory_usage() ### monitor memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    ">>> LOADING ALL NECESSARY DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The following function is used to check the parquet file to ensure that the string values are not in bytes format and if they are to convert them back to string\n",
    "### This function is found in the pre_processing_fnc folder\n",
    "### check your dataframe first before using as it is not required for all inputs\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Description: Read parquet file and return a pandas dataframe\n",
    "def check_parquet(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':  # Check if column is of object type\n",
    "            df[col] = df[col].apply(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "    return df\n",
    "# ------------\n",
    "\n",
    "### we will load 3 files here: cell_feature_matrix.h5, cells.parquet and transcripts.parquet\n",
    "### We will check the parquet file to ensure that the string values are not in bytes format and if they are to convert them back to string\n",
    "df_cell = check_parquet(os.path.join(data_dir+datasets_to_use ,cells_filename))\n",
    "df_transcript = check_parquet(os.path.join(data_dir+datasets_to_use, transcripts_filename))\n",
    "df_metric = pd.read_csv(os.path.join(data_dir+datasets_to_use, metrices_filename))\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------\n",
    "get_memory_usage() ### monitor memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    ">>> RUN THE NEXT CELL AND REVIEW THE COLUMNS OF THE DATAFRAME AND TRY TO ANSWER THE QUESTIONS GIVEN BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcript\n",
    "\n",
    "### Look at the transcript dataframe and what do you see? What are the columns? What are the values? What are the data types?\n",
    "### Which columns are important for our analysis? \n",
    "### What is fov?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    ">>> START THE PROCESS OF QC <BR>\n",
    ">>> STEP 1 : LABEL THE TRANSCRIPTS WELL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "### The process_data function is a wrapper that does the following\n",
    "1. The transcripts are derived from either gene or control probes\n",
    "2. There are 3 different types of control probes : Negative codewords, Negative probes and Blank probes. The first two begin with Neg* and the last one begins with BLANK*\n",
    "3. In this tutorial, we label all control probes as neg_probes and all gene-derived transcripts as gene_probes\n",
    "4. We also label the transcripts as assigned to a cell or not assigned to a cell. Note this initial assigment is based from the cell segmentation from the standard xenium clear_output\n",
    "\"\"\"\n",
    "#### imports transcript csv file and removed the negative control probes.\n",
    "#### assigns binary labels to assigned and unassigned cells\n",
    "### this function is found in the pre_processing_fnc folder\n",
    "\n",
    "def process_data(tf):\n",
    "    ### filter out negative control probes\n",
    "    df_neg = tf[tf.feature_name.str.contains('BLANK|Neg', regex=True)].copy()\n",
    "    df_neg['group'] = 'neg_probes'\n",
    "\n",
    "    ### filter out transcripts that are genes\n",
    "    df_genes = tf[~tf['transcript_id'].isin(df_neg.transcript_id)].copy()\n",
    "    df_genes['group'] = 'gene_probes'\n",
    "    \n",
    "    df = pd.concat([df_neg, df_genes], axis=0)\n",
    "\n",
    "    ### ensure that index for df is equal to original tf\n",
    "    df.set_index(tf.index, inplace=True)\n",
    "\n",
    "    ### assign binary labels to assigned and unassigned cells\n",
    "    df.loc[df.cell_id == 'UNASSIGNED', 'binary'] = 'unassigned'\n",
    "    df.loc[df.cell_id != 'UNASSIGNED', 'binary'] = 'assigned'\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "### execute function\n",
    "processed_data = process_data(df_transcript) ### we process and assign the output to an object called processed_data\n",
    "del df_transcript ### we delete the original transcript dataframe to save memory\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------\n",
    "get_memory_usage() ### monitor memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    ">>> RUN THE NEXT CELL AND OBSERVE THE ADDITIONAL COLUMNS ON YOUR FAR RIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data.head()\n",
    "### note the additional columns added to the processed_data dataframe : group and binary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now it is important to understand the quality of transcripts. \n",
    "* This is an image-based system. There are many facets of the experimental process that will affect the quality of the tissue.\n",
    "* The purpose of \"Module 1 : Garbage-in, Garbage-out\" was to highlight this. \n",
    "* Therefore, review these steps carefully as it will help you identify if you need to \"quarantine\" certain regions from downstream processing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    ">>> THE NEXT TWO CODE BLOCKS SHOW THE OVERALL QUALITY ASSESSMENT OF THE TRANSCRIPTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B1. QUALITY ASSESSEMENT\n",
    "* Lets look at some plots that will assess the quality of these imaged transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4.5, 4.5))\n",
    "\n",
    "fig.suptitle('B1A.Transcript quality values (QV) distribution between control and gene-probe derived transcripts', fontsize=9)\n",
    "sns.violinplot(x='group', y='qv', data=processed_data, hue='binary', split=True, inner='quartile', ax=ax, palette=['#ebac23', '#b80058'])\n",
    "ax.set_ylim(0, 50)\n",
    "ax.xaxis.set_tick_params(rotation=45, labelsize=9)\n",
    "ax.set_xlabel('')\n",
    "sns.despine()\n",
    "plt.legend(title='Assignment status', loc='upper right', bbox_to_anchor=(1, 1.2))\n",
    "plt.tight_layout(rect=[0, 0, 1.25, 0.95])\n",
    "#plt.savefig(out+'B1A.Transcript_quality_values_distribution.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "#------------------------------------------------\n",
    "get_memory_usage() ### monitor memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot the proportion of neg and positive probes and the proportion of assigned and unassigned probes\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4.5))\n",
    "\n",
    "fig.suptitle('B1B. Proportion of probes as a fraction of the whole tissue', fontsize=12, fontweight='bold', y=1.05, x=0.01)\n",
    "ax = processed_data['binary'].value_counts(normalize=True).plot(kind='bar', ax=axes[0])\n",
    "ax.set_title('A. Proportion of negativ and positive probes', fontsize=9, loc='left')\n",
    "ax.xaxis.set_tick_params(rotation=45)\n",
    "\n",
    "ax = processed_data['group'].value_counts(normalize=True).plot(kind='bar', ax=axes[1])\n",
    "ax.set_title('B. Proportion of assigned and unassigned probes', fontsize=9, loc='left')\n",
    "ax.xaxis.set_tick_params(rotation=45)\n",
    "\n",
    "ax = processed_data.groupby(['group', 'binary']).size().unstack().plot(kind='bar', stacked=False, ax=axes[2])\n",
    "ax.set_title('C. Proportion of negativ and positive probes by assignment', fontsize=9, loc='left')\n",
    "ax.xaxis.set_tick_params(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "### save the values above into a table for each sample\n",
    "binary_proportion = processed_data['binary'].value_counts(normalize=True),\n",
    "group_proportion = processed_data['group'].value_counts(normalize=True),\n",
    "group_binary_proportion = processed_data.groupby(['group', 'binary']).size().unstack()\n",
    "\n",
    "binary_proportion = pd.DataFrame(binary_proportion)\n",
    "group_proportion = pd.DataFrame(group_proportion)\n",
    "group_binary_proportion = pd.DataFrame(group_binary_proportion)\n",
    "\n",
    "dfs = [binary_proportion, group_proportion, group_binary_proportion]\n",
    "titles = ['Binary Proportion', 'Group Proportion', 'Group Binary Proportion']\n",
    "\n",
    "\n",
    "### THis function is found in the pre_processing_fnc folder\n",
    "### display the tables and the corresponding plots side by side\n",
    "\n",
    "def display_side_by_side(dfs, titles=[]):\n",
    "    \"\"\"\n",
    "    Display DataFrames side by side in Jupyter Notebook.\n",
    "    \n",
    "    Parameters:\n",
    "    dfs (list): List of DataFrames or tuples to display.\n",
    "    titles (list): List of titles for the DataFrames (optional).\n",
    "    \"\"\"\n",
    "    html_str = ''\n",
    "    \n",
    "    for i, df in enumerate(dfs):\n",
    "        # Convert tuples to DataFrames if necessary\n",
    "        if isinstance(df, tuple):\n",
    "            df = pd.DataFrame(df)\n",
    "        elif not isinstance(df, pd.DataFrame):\n",
    "            raise TypeError(f\"Expected pd.DataFrame or tuple, but got {type(df)} at index {i}\")\n",
    "        \n",
    "        title = f'<h3>{titles[i]}</h3>' if i < len(titles) else ''\n",
    "        html_str += f'<td>{title}{df.to_html()}</td>'\n",
    "    \n",
    "    display(HTML(f\"\"\"\n",
    "    <table>\n",
    "        <tr>{html_str}</tr>\n",
    "    </table>\n",
    "    \"\"\"))\n",
    "\n",
    "\n",
    "### display the tables    \n",
    "display_side_by_side(dfs, titles)\n",
    "\n",
    "#------------------------------------------------\n",
    "get_memory_usage() ### monitor memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now let's look at the quality value of transcripts as they are distributed across the tissue area.\n",
    "* It is important to look at the distribution of your low and high quality transcripts as this reflects the underlying tissue \"health\" that can help guide further image processing or transcript inclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    ">>> NOW WE WILL RUN THE NEXT THREE CODE BLOCK WHICH WILL BREAK THE QUALITY ASSESSMENT INTO FOVS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming processed_data is already defined and loaded as a DataFrame\n",
    "# Reorder the fov_name based on the mean qv values\n",
    "\n",
    "fov_mean = processed_data.groupby('fov_name')['qv'].mean().reset_index()\n",
    "fov_mean = fov_mean.sort_values('qv', ascending=False)\n",
    "processed_data['fov_name'] = pd.Categorical(processed_data['fov_name'], fov_mean['fov_name'])\n",
    "\n",
    "# Plot directly into the axes\n",
    "g = sns.FacetGrid(processed_data, col='group', col_wrap=1, height=2.5, aspect=6, sharey=True, sharex=True, despine=True)\n",
    "\n",
    "# Mapping the boxplot\n",
    "g.map_dataframe(sns.boxplot, x='fov_name', y='qv', hue='binary', palette=['#ebac23', '#b80058'], showfliers=False)\n",
    "\n",
    "# Customize the FacetGrid\n",
    "for ax in g.axes.flat:\n",
    "    ax.set_ylim(0, 40)\n",
    "    ax.axhline(20, color='red', linestyle='dashed')\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles=handles, labels=labels, loc='upper right', fontsize=9, bbox_to_anchor=(1.15, 1.15))\n",
    "    # Shift title to the left\n",
    "\n",
    "# Remove the additional title\n",
    "g.figure.suptitle('B1C. QV values per FOV', y=1.05, x=0.1, fontsize=12, fontweight='bold', color='darkblue')\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "#plt.savefig(out+'B1C.QV_values_per_fov.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------\n",
    "get_memory_usage() ### monitor memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The fov_plot function allows us to plot the field of view (FOV) images that saves time for participants to visualize the data.\n",
    "### This function is found in the pre_processing_fnc folder\n",
    "\n",
    "def fov_plot(processed_data, plot_qv=True, ax=None, identifier=['gene_probes', 'neg_probes']):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()  # Create figure and axis internally if not provided\n",
    "\n",
    "    if plot_qv:\n",
    "        qv_min = 0\n",
    "        qv_max = 40\n",
    "        cmap = plt.get_cmap('viridis')\n",
    "        norm = mcolors.Normalize(vmin=qv_min, vmax=qv_max)\n",
    "    else:\n",
    "        cmap = None\n",
    "        norm = None\n",
    "\n",
    "    grouped = processed_data.groupby('fov_name')\n",
    "    \n",
    "    for fov, group in grouped:\n",
    "        if group.shape[0] > 0:\n",
    "            x = group['x_location'].values\n",
    "            y = group['y_location'].values\n",
    "            xy00 = (x.min(), y.min())\n",
    "            xy01 = (x.min(), y.max())\n",
    "            xy10 = (x.max(), y.min())\n",
    "            xy11 = (x.max(), y.max())\n",
    "            xy = [xy00, xy01, xy11, xy10, xy00]\n",
    "\n",
    "            group_assigned = group[group['binary'] == 'assigned']\n",
    "        \n",
    "            if plot_qv:\n",
    "                qv_avg = None\n",
    "                if (group_assigned['group'] == identifier).any():\n",
    "                    qv_avg = group_assigned.loc[group_assigned['group'] == identifier, 'qv'].mean()\n",
    "                elif (group_assigned['group'] == identifier).any():\n",
    "                    qv_avg = group_assigned.loc[group['group'] == identifier, 'qv'].mean()\n",
    "                \n",
    "                if qv_avg is not None:\n",
    "                    color = cmap(norm(qv_avg))\n",
    "                    alpha = 0.5\n",
    "                    ax.fill(*zip(*xy), color=color, alpha=alpha, edgecolor=color, linewidth=0)\n",
    "                else:\n",
    "                    color = 'none'\n",
    "                    alpha = 0\n",
    "                    ax.fill(*zip(*xy), color=color, alpha=alpha, edgecolor=color, linewidth=0)\n",
    "            else:\n",
    "                color = 'none'\n",
    "                alpha = 0\n",
    "                ax.fill(*zip(*xy), color=color, alpha=alpha, edgecolor=color, linewidth=0)\n",
    "\n",
    "            ax.plot(*zip(*xy), color='black', linewidth=0.5)\n",
    "\n",
    "            centroid_x = (x.min() + x.max()) / 2\n",
    "            centroid_y = (y.min() + y.max()) / 2\n",
    "\n",
    "            ax.text(centroid_x, centroid_y, fov, fontsize=8, ha='center', va='center_baseline', color='black')\n",
    "    \n",
    "    if plot_qv:\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        sm.set_array([])\n",
    "        cbar = ax.figure.colorbar(sm, ax=ax)\n",
    "        cbar.set_label('Quality value (qv)')\n",
    "    \n",
    "    if ax is None:\n",
    "        plt.show()  # Only show plot if created internally\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4.5))\n",
    "fig.suptitle('B1D. QV values per FOV - plotted as a grid', fontsize=12, fontweight='bold', y=1.05, x=0.15)\n",
    "\n",
    "### Execute the function\n",
    "fov_plot(processed_data, plot_qv=True, identifier='gene_probes', ax=ax[0])\n",
    "ax[0].set_title('A. Gene probes', fontsize=9, loc='left')\n",
    "\n",
    "fov_plot(processed_data, plot_qv=True, identifier='neg_probes', ax=ax[1])\n",
    "ax[1].set_title('B. Control probes', fontsize=9, loc='left')\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.savefig(out+'B1D.QV_values_per_fov_grid.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#------------------------------------------------\n",
    "get_memory_usage() ### monitor memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Function to plot the gene and negative transcripts and assess their QV values\n",
    "### This function is found in the pre_processing_fnc folder\n",
    "def plot_gene_and_neg_transcripts(processed_data, type='molecule'):\n",
    "    gene_assigned = processed_data[(processed_data['binary'] == 'assigned') & (processed_data['group'] == 'gene_probes')].copy()\n",
    "    neg_assigned = processed_data[(processed_data['group'] == 'neg_probes') & (processed_data['binary'] == 'assigned')].copy()\n",
    "\n",
    "    if type == 'molecule':\n",
    "        gene_assigned = gene_assigned.sample(n=neg_assigned.shape[0]*2, random_state=42)\n",
    "        data_list = [gene_assigned, neg_assigned]\n",
    "\n",
    "    elif type == 'mean_fov':\n",
    "        grouped_neg = neg_assigned.groupby('fov_name')\n",
    "        neg_mean = []\n",
    "        for fov, group in grouped_neg:\n",
    "            if group.shape[0] > 0:\n",
    "                x = group['x_location'].values\n",
    "                y = group['y_location'].values\n",
    "                centroid_x = (x.min() + x.max()) / 2\n",
    "                centroid_y = (y.min() + y.max()) / 2\n",
    "                qv_avg = group['qv'].mean()\n",
    "                neg_mean.append({'fov_name': fov, 'x_location': centroid_x, 'y_location': centroid_y, 'qv': qv_avg})\n",
    "        \n",
    "        neg_mean = pd.DataFrame(neg_mean)\n",
    "        \n",
    "        grouped_gene = gene_assigned.groupby('fov_name')\n",
    "        gene_mean = []\n",
    "        for fov, group in grouped_gene:\n",
    "            if group.shape[0] > 0:\n",
    "                x = group['x_location'].values\n",
    "                y = group['y_location'].values\n",
    "                centroid_x = (x.min() + x.max()) / 2\n",
    "                centroid_y = (y.min() + y.max()) / 2\n",
    "                qv_avg = group['qv'].mean()\n",
    "                gene_mean.append({'fov_name': fov, 'x_location': centroid_x, 'y_location': centroid_y, 'qv': qv_avg})\n",
    "\n",
    "        gene_mean = pd.DataFrame(gene_mean)\n",
    "        data_list = [gene_mean, neg_mean]\n",
    "        \n",
    "    # Create a figure and axis\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(13, 4.5))\n",
    "\n",
    "    for i, df in enumerate(data_list):\n",
    "        df = df.sort_values('qv', ascending=True)\n",
    "        sns.scatterplot(x='x_location', y='y_location', data=df, hue='qv', palette='viridis', s=1, ax=axs[i], legend=False)\n",
    "        axs[i].set_xlabel('')\n",
    "        axs[i].set_ylabel('')\n",
    "        sns.despine()\n",
    "\n",
    "        norm = plt.Normalize(vmin=0, vmax=40)\n",
    "        sm = plt.cm.ScalarMappable(cmap='viridis', norm=norm)\n",
    "        sm.set_array([])\n",
    "\n",
    "        cbar = fig.colorbar(sm, ax=axs[i], ticks=[0, 20, 40])\n",
    "        cbar.set_label('Quality value', labelpad=15)\n",
    "        \n",
    "        fov_plot(processed_data, plot_qv=False, ax=axs[i])\n",
    "        axs[i].set_title('Gene probes' if i == 0 else 'Negative control probes')\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "### Execute the function\n",
    "fig.suptitle('B1E. QV values of each transcript - plotted as a grid', fontsize=12, fontweight='bold', y=1.05, x=0.15)\n",
    "plot_gene_and_neg_transcripts(processed_data)\n",
    "#plt.savefig(out+'B1E.QV_values_per_transcript_grid.png', dpi=300)\n",
    "\n",
    "\n",
    "#------------------------------------------------\n",
    "get_memory_usage() ### monitor memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    ">>> STOP FOR DISCUSSION / START LECTURE <BR>\n",
    ">>> WHAT'S THE SIGNIFICANCE OF GOING THROUGH THIS PROCESS OF SPLITTING BY FOV? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    ">>> NOW WE WILL CLEAN THE TRANSCRIPTS FILE AND PROCESS THE DATA TO CREATE THE FOLLOWING THREE FILES \n",
    "* MATRIX FILE - cell x genes = cell.csv output\n",
    "* COORDINATE FILE\n",
    "* COUNTS FILE\n",
    "\n",
    "WE WILL USE THE THREE TO CREATE AN ANNDATA OBJECT <BR>\n",
    "10X PROVIDES A CLEANED UP VERSION IN THE XENIUM OUTPUT <BR>\n",
    "WE ARE CREATING THESE FILES FROM THE TRANSCRIPTS FILE <BR>\n",
    "    * UNDERSTAND THE PROCESS <BR>\n",
    "    * SEGMENTATION (REQUIRES THE USE OF THE TRANSCRIPTS FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> B2. NOW WE CAN DECIDE TO CLEAN OUR DATASETS BASED ON\n",
    "1. Choice of QV cut-off : standard practise is to use QV > 20 but this can be changed\n",
    "2. Keep all or discard certain FOVs.\n",
    "3. Check for edge-effects and decide to drop transcripts covering the borders\n",
    "4. Choose to re-evaluate images (H&E or IF images if necessary) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The cleaned data is then used to create the gene matrix, control matrix, counts matrix and cell centroid matrix \n",
    "Here, it involves removing low quality transcripts and assigning the transcripts to the cells based on the cell segmentation from the standard xenium clear_output\n",
    "We still keep the negative control values as a separate matrix\n",
    "\n",
    "However the 3 matrices that we will bring forward to the next lesson are\n",
    "1. gene matrix\n",
    "2. counts matrix\n",
    "3. cell centroid matrix\n",
    "\"\"\"\n",
    "\n",
    "### This function is found in the pre_processing_fnc folder\n",
    "\n",
    "def clean_processed_tf(processed_data, qv=20):\n",
    "    # Filter for gene probes that are assigned\n",
    "    gene_assigned = processed_data[(processed_data['binary'] == 'assigned') & (processed_data['group'] == 'gene_probes')].copy()\n",
    "    # Filter for negative probes that are assigned\n",
    "    neg_assigned = processed_data[(processed_data['group'] == 'neg_probes') & (processed_data['binary'] == 'assigned')].copy()\n",
    "    \n",
    "    # Subset for transcripts with qv > 20\n",
    "    gene_qv_tf = gene_assigned[gene_assigned['qv'] > qv].copy()\n",
    "\n",
    "    # Group by cell_id and feature_name, then count the number of transcripts\n",
    "    gene_qv = gene_qv_tf.groupby(['cell_id', 'feature_name'])['transcript_id'].size().reset_index(name='transcript_count')\n",
    "    # Pivot table to create a matrix of transcript counts\n",
    "    gene_mtx = gene_qv.pivot_table(index='cell_id', columns='feature_name', values='transcript_count').fillna(0)\n",
    "    new_gene_mtx = pd.DataFrame(gene_mtx.values, columns=gene_mtx.columns, index=gene_mtx.index)\n",
    "    new_gene_mtx.index.name = None\n",
    "    new_gene_mtx = new_gene_mtx.rename_axis(None, axis=1)\n",
    "\n",
    "    # Repeat for negative probes\n",
    "    neg_qv = neg_assigned[neg_assigned['qv'] > qv].copy()\n",
    "    neg_qv = neg_qv.groupby(['cell_id', 'feature_name'])['transcript_id'].size().reset_index(name='transcript_count')\n",
    "    neg_mtx = neg_qv.pivot_table(index='cell_id', columns='feature_name', values='transcript_count').fillna(0)\n",
    "    new_neg_mtx = pd.DataFrame(neg_mtx.values, columns=neg_mtx.columns, index=neg_mtx.index)\n",
    "    new_neg_mtx.index.name = None    \n",
    "    new_gene_mtx = new_gene_mtx.rename_axis(None, axis=1)\n",
    "    \n",
    "    # Sum the counts across features for each cell\n",
    "    gene_counts = gene_mtx.sum(axis=1)\n",
    "    neg_counts = neg_mtx.sum(axis=1)\n",
    "\n",
    "    df_counts = pd.concat([gene_counts, neg_counts], axis=1)\n",
    "    df_counts.columns = ['total_counts', 'neg_counts']\n",
    "    df_counts = df_counts.fillna(0)\n",
    "\n",
    "    ### calculate centroids\n",
    "    gene_qv = gene_assigned[gene_assigned['qv'] > qv].copy()\n",
    "    centroids = gene_qv.groupby('cell_id')[['x_location', 'y_location']].mean().reset_index()\n",
    "    centroids.columns = ['cell_id', 'centroid_x', 'centroid_y']\n",
    "    centroids.set_index('cell_id', inplace=True)\n",
    "    new_centroids = pd.DataFrame(centroids.values, columns=centroids.columns, index=centroids.index)\n",
    "    new_centroids.index.name = None\n",
    "    new_centroids = new_centroids.rename_axis(None, axis=1)\n",
    "    \n",
    "    return df_counts, gene_qv_tf, new_gene_mtx, new_neg_mtx, centroids\n",
    "\n",
    "\n",
    "### execute the function\n",
    "df_counts, transcripts_df, gene_mtx, neg_mtx, centroids = clean_processed_tf(processed_data)\n",
    "\n",
    "\n",
    "#------------------------------------------------\n",
    "get_memory_usage() ### monitor memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at each matrix and note how these are now your standard single cell matrices that you are probably used to working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_mtx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> FURTHER QUALITY CONTROL <br>\n",
    "\n",
    "It is important to ensure we keep cells that express a minimum number of transcripts and genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now evaluate the number of genes expressed by each cell and plot a distribution plot for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### evaluate the distribution of genes expressed per cell\n",
    "gene_mtx_bool = gene_mtx > 0\n",
    "gene_counts = gene_mtx_bool.sum(axis=1)\n",
    "gene_counts.plot(kind='hist', bins=150, color='darkblue', edgecolor=None)\n",
    "plt.vlines(gene_counts.mean(), 0, 1700, color='red', linestyle='dashed')\n",
    "plt.vlines(gene_counts.median(), 0, 1700, color='green', linestyle='dashed')\n",
    "plt.vlines(gene_counts.mode(), 0, 1700, color='yellow', linestyle='dashed')\n",
    "plt.vlines(gene_counts.quantile(0.02), 0, 1700, color='black', linestyle='dashed')\n",
    "\n",
    "\n",
    "### label the plot\n",
    "plt.title('B2A. Distribution of genes expressed per cell', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Number of genes expressed')\n",
    "plt.ylabel('Number of cells')\n",
    "plt.legend(['Genes', 'Mean', 'Median', 'Mode', '2nd percentile'], loc='upper right')\n",
    "#plt.savefig(out+'B2A.Distribution_of_genes_expressed_per_cell.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_counts.quantile(0.02)\n",
    "\n",
    "### what would a reasonable threshold be for the number of genes expressed per cell?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can decide what's the minimum number of genes we want to exclude "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will use the df_counts file to plot the distrbution of control and gene-derived transcript distribution. We can clearly see that using a threshold of discarding any cell having less than 10 cells is reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15.5, 3.9))\n",
    "ax = sns.histplot(df_counts, x='neg_counts', bins=100, color='#8a034f', alpha=0.5, ax=axes[0], linewidth=0.1)\n",
    "ax = sns.histplot(df_counts, x='total_counts', bins=100, alpha=0.5, ax=axes[0], color='#005a8a', linewidth=0.1)\n",
    "ax.set_title('A. All counts from gene and negative probes', loc='left', color='black')\n",
    "ax.set_xlabel('Counts')\n",
    "ax.set_ylabel('Cell frequency')\n",
    "ax.legend(['Negative probes', 'Gene probes'])\n",
    "\n",
    "ax = sns.histplot(df_counts, x='neg_counts', bins=100, color='#8a034f', alpha=0.5, ax=axes[1], linewidth=0.1)\n",
    "ax = sns.histplot(df_counts, x='total_counts', bins=100, alpha=0.5, ax=axes[1], color='#005a8a', linewidth=0.1)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Counts')\n",
    "ax.set_ylabel('Cell frequency')\n",
    "ax.set_title('B. Log scale of plot A' , loc='left', color='blue')\n",
    "ax.legend(['Negative probes', 'Gene probes'])\n",
    "\n",
    "ax = sns.histplot(df_counts, x='neg_counts', bins=100, color='#8a034f', alpha=0.5, ax=axes[2], linewidth=0.1)\n",
    "#sns.histplot(df_counts, x='total_counts', bins=100, alpha=0.5, ax=ax, color='blue')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Counts')\n",
    "ax.set_ylabel('Cell frequency')\n",
    "ax.set_title('C. Negative counts only', loc='left', color='red')\n",
    "ax.legend(['Negative probes'])\n",
    "\n",
    "fig.suptitle('B2B. Distribution of counts from gene and negative probes', fontsize=12, fontweight='bold', y=1.05, x=0.3)\n",
    "#plt.savefig(out+'B2B.Distribution_of_counts.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------\n",
    "get_memory_usage() ### monitor memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, remember & remember to save your file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create folder with sample name to save files\n",
    "os.makedirs(out+'TgCRND8_17_8mths', exist_ok=True)\n",
    "\n",
    "df_counts.to_csv(out+'TgCRND8_17_8mths/df_counts.csv', index=True)\n",
    "gene_mtx.to_csv(out+'TgCRND8_17_8mths/gene_mtx.csv', index=True)\n",
    "neg_mtx.to_csv(out+'TgCRND8_17_8mths/neg_mtx.csv', index=True)\n",
    "centroids.to_csv(out+'TgCRND8_17_8mths/centroids.csv', index=True)\n",
    "transcripts_df.to_csv(out+'TgCRND8_17_8mths/transcripts_df.csv', index=True)\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------\n",
    "get_memory_usage() ### monitor memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Next, let's finally create single cell like object that will store our gene matrix, counts matrix and centroid information in the right order.\n",
    "* In this workshop, we will use the AnnData container to store all our frames. In practise, you can use any S4 container to do so - as long as you slot them in properly.\n",
    "* In the next steps, we will perform the final clean-up  by removing low transcript cells (as determined above) and also to take note of the median/mean expression of transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_mtx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> CREATING AN ANDATA OBJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.AnnData(X=gene_mtx, var=pd.DataFrame(index=gene_mtx.columns.values))\n",
    "\n",
    "df_counts = df_counts[df_counts.index.isin(gene_mtx.index)]\n",
    "\n",
    "df_counts = df_counts.reindex(gene_mtx.index)\n",
    "adata.obs = df_counts.copy()\n",
    "    \n",
    "centroids = centroids.reindex(adata.obs.index)\n",
    "adata.obs[['x_location', 'y_location']] = centroids[['centroid_x', 'centroid_y']].values\n",
    "\n",
    "gene_mtx_bool = gene_mtx > 0\n",
    "n_cells = gene_mtx_bool.sum(axis=0)\n",
    "n_genes = gene_mtx_bool.sum(axis=1)\n",
    "\n",
    "adata.var['n_cells'] = n_cells\n",
    "adata.obs['n_genes'] = n_genes\n",
    "\n",
    "sc.pp.filter_genes(adata, min_cells=3)\n",
    "sc.pp.filter_cells(adata, min_counts=9)\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------\n",
    "get_memory_usage() ### monitor memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Always remember to save the coordinates of the spatial data in the adata object into the uns and obsm slots. Many methods call the spatial coordinates from these slots\n",
    "\n",
    "adata.obsm['spatial'] = adata.obs[['x_location', 'y_location']].values\n",
    "adata.uns['spatial'] = {'spatial' : adata.obsm['spatial'].copy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save your adata\n",
    "adata.raw = adata\n",
    "adata.write(out+'TgCRND8_17_8mths/adata.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "C. Gene Coverage\n",
    "```\n",
    "\n",
    "We will briefly review the genes and the probeset coverage for each gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python libraries\n",
    "# Example with Python v3.12, pandas v2.1.1\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Open JSON file\n",
    "f = open(data_dir+'mice_AD_model/TgCRND8/xenium_out/gene_panel.json') # Edit file name here\n",
    "\n",
    "# Return JSON object as a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "# Create lists to store extracted information\n",
    "gene = []\n",
    "ensembl = []\n",
    "cov = []\n",
    "# Iterate through the JSON list to extract information\n",
    "for i in data['payload']['targets']:\n",
    "    if (i['type']['descriptor'] == \"gene\"): # Only collect info for genes, not controls\n",
    "        gene_name = i['type']['data']['name']\n",
    "        ensembl_id = i['type']['data']['id']\n",
    "        coverage = str(i['info']['gene_coverage'])\n",
    "\n",
    "        gene.append(gene_name)\n",
    "        ensembl.append(ensembl_id)\n",
    "        cov.append(coverage)\n",
    "\n",
    "# Create output CSV file\n",
    "out_df = pd.DataFrame(list(zip(gene, ensembl, cov)), columns=['Gene name', 'Ensembl ID', 'Gene coverage'])\n",
    "#out_df.to_csv(out+'my_panel_gene_info.csv', index=False)\n",
    "\n",
    "# Close file\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "\n",
    "fig.suptitle('B2C. Gene coverage distribution', fontsize=12, fontweight='bold', y=1.05, x=0.15)\n",
    "out_df['Gene coverage'].value_counts(normalize=True).plot(kind='bar', color='darkblue', edgecolor='black')\n",
    "ax.set_title('Gene coverage distribution', fontsize=9, loc='left')\n",
    "ax.set_xlabel('Gene coverage')\n",
    "ax.set_ylabel('Proportion of genes')\n",
    "plt.savefig(out+'B2C.Gene_coverage_distribution.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> END OF MODULE 2 : Pre-processing steps <br>\n",
    "> Thank you and see you in the next lecture where we will tackle spatial clustering"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xenium",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
